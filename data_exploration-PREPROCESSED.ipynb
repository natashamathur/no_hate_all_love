{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.float_format = '{:20.4f}'.format\n",
    "\n",
    "import _pickle as cPickle\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import boto3.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code modified from:  https://github.com/noopurrkalawatia/Dhvani/blob/master/Boto3_features.ipynb\n",
    "\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "s3client = session.client('s3')\n",
    "\n",
    "response = s3client.get_object(Bucket='advancedml-koch-mathur-hinkson', Key='sub_train_df1_preprocessed.pkl')\n",
    "\n",
    "body_string = response['Body'].read()\n",
    "data = cPickle.loads(body_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
       "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
       "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
       "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
       "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
       "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
       "       'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count', 'split',\n",
       "       'cleaned_w_stopwords_str', 'cleaned_w_stopwords', 'cleaned_no_stem_str',\n",
       "       'cleaned_no_stem', 'cleaned_porter_str', 'cleaned_porter',\n",
       "       'cleaned_lancaster_str', 'cleaned_lancaster', 'bigrams_unstemmed',\n",
       "       'perc_upper', 'num_exclam', 'num_words', 'perc_stopwords',\n",
       "       'num_upper_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toxicity_category'] = data.target.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "toxic = data[data.toxicity_category == 1]\n",
    "nontoxic = data[data.toxicity_category == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>cleaned_porter</th>\n",
       "      <th>cleaned_lancaster_str</th>\n",
       "      <th>cleaned_lancaster</th>\n",
       "      <th>bigrams_unstemmed</th>\n",
       "      <th>perc_upper</th>\n",
       "      <th>num_exclam</th>\n",
       "      <th>num_words</th>\n",
       "      <th>perc_stopwords</th>\n",
       "      <th>num_upper_words</th>\n",
       "      <th>toxicity_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>[haha, guy, bunch, loser]</td>\n",
       "      <td>hah guy bunch los</td>\n",
       "      <td>[hah, guy, bunch, los]</td>\n",
       "      <td>[haha guys, guys bunch, bunch losers]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59859</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>[ur, sh*tti, comment]</td>\n",
       "      <td>ur sh*tty com</td>\n",
       "      <td>[ur, sh*tty, com]</td>\n",
       "      <td>[ur sh*tty, sh*tty comment]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>239583</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>[it', ridicul, guy, call, protest, be, arm, th...</td>\n",
       "      <td>it's ridic guy cal protest being arm threat vi...</td>\n",
       "      <td>[it's, ridic, guy, cal, protest, being, arm, t...</td>\n",
       "      <td>[it's ridiculous, ridiculous guys, guys called...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>239607</td>\n",
       "      <td>0.9125</td>\n",
       "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>[yet, call, muslim, act, get, pillori, so, oka...</td>\n",
       "      <td>yet cal muslim act get pil so okay smear entir...</td>\n",
       "      <td>[yet, cal, muslim, act, get, pil, so, okay, sm...</td>\n",
       "      <td>[yet call, call muslims, muslims acts, acts ge...</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>239612</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>This bitch is nuts. Who would read a book by a...</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>0.3385</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>[thi, bitch, nut, who, would, read, book, woman]</td>\n",
       "      <td>thi bitch nut who would read book wom</td>\n",
       "      <td>[thi, bitch, nut, who, would, read, book, wom]</td>\n",
       "      <td>[this bitch, bitch nuts, nuts who, who would, ...</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               target  \\\n",
       "4    59856               0.8936   \n",
       "5    59859               0.6667   \n",
       "13  239583               0.6000   \n",
       "31  239607               0.9125   \n",
       "34  239612               0.8308   \n",
       "\n",
       "                                         comment_text      severe_toxicity  \\\n",
       "4                haha you guys are a bunch of losers.               0.0213   \n",
       "5                                ur a sh*tty comment.               0.0476   \n",
       "13  It's ridiculous that these guys are being call...               0.0000   \n",
       "31  Yet call out all Muslims for the acts of a few...               0.0500   \n",
       "34  This bitch is nuts. Who would read a book by a...               0.1077   \n",
       "\n",
       "                obscene      identity_attack               insult  \\\n",
       "4                0.0000               0.0213               0.8723   \n",
       "5                0.6381               0.0000               0.3333   \n",
       "13               0.1000               0.0000               0.6000   \n",
       "31               0.2375               0.6125               0.8875   \n",
       "34               0.6615               0.3385               0.8308   \n",
       "\n",
       "                 threat                asian              atheist  ...  \\\n",
       "4                0.0000               0.0000               0.0000  ...   \n",
       "5                0.0000                  nan                  nan  ...   \n",
       "13               0.1000                  nan                  nan  ...   \n",
       "31               0.1125               0.0000               0.0000  ...   \n",
       "34               0.0000               0.0000               0.0000  ...   \n",
       "\n",
       "                                       cleaned_porter  \\\n",
       "4                           [haha, guy, bunch, loser]   \n",
       "5                               [ur, sh*tti, comment]   \n",
       "13  [it', ridicul, guy, call, protest, be, arm, th...   \n",
       "31  [yet, call, muslim, act, get, pillori, so, oka...   \n",
       "34   [thi, bitch, nut, who, would, read, book, woman]   \n",
       "\n",
       "                                cleaned_lancaster_str  \\\n",
       "4                                   hah guy bunch los   \n",
       "5                                       ur sh*tty com   \n",
       "13  it's ridic guy cal protest being arm threat vi...   \n",
       "31  yet cal muslim act get pil so okay smear entir...   \n",
       "34              thi bitch nut who would read book wom   \n",
       "\n",
       "                                    cleaned_lancaster  \\\n",
       "4                              [hah, guy, bunch, los]   \n",
       "5                                   [ur, sh*tty, com]   \n",
       "13  [it's, ridic, guy, cal, protest, being, arm, t...   \n",
       "31  [yet, cal, muslim, act, get, pil, so, okay, sm...   \n",
       "34     [thi, bitch, nut, who, would, read, book, wom]   \n",
       "\n",
       "                                    bigrams_unstemmed           perc_upper  \\\n",
       "4               [haha guys, guys bunch, bunch losers]               0.0000   \n",
       "5                         [ur sh*tty, sh*tty comment]               0.0000   \n",
       "13  [it's ridiculous, ridiculous guys, guys called...               0.0160   \n",
       "31  [yet call, call muslims, muslims acts, acts ge...               0.0260   \n",
       "34  [this bitch, bitch nuts, nuts who, who would, ...               0.0380   \n",
       "\n",
       "    num_exclam  num_words       perc_stopwords  num_upper_words  \\\n",
       "4            0          8               0.5000                0   \n",
       "5            0          4               0.2500                0   \n",
       "13           0         20               0.4000                0   \n",
       "31           0         42               0.5710                0   \n",
       "34           0         12               0.3330                0   \n",
       "\n",
       "    toxicity_category  \n",
       "4                   1  \n",
       "5                   1  \n",
       "13                  1  \n",
       "31                  1  \n",
       "34                  1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
       "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
       "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
       "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
       "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
       "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
       "       'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count', 'split',\n",
       "       'cleaned_w_stopwords_str', 'cleaned_w_stopwords', 'cleaned_no_stem_str',\n",
       "       'cleaned_no_stem', 'cleaned_porter_str', 'cleaned_porter',\n",
       "       'cleaned_lancaster_str', 'cleaned_lancaster', 'bigrams_unstemmed',\n",
       "       'perc_upper', 'num_exclam', 'num_words', 'perc_stopwords',\n",
       "       'num_upper_words', 'toxicity_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment_length'] = data[\"comment_text\"].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>cleaned_lancaster_str</th>\n",
       "      <th>cleaned_lancaster</th>\n",
       "      <th>bigrams_unstemmed</th>\n",
       "      <th>perc_upper</th>\n",
       "      <th>num_exclam</th>\n",
       "      <th>num_words</th>\n",
       "      <th>perc_stopwords</th>\n",
       "      <th>num_upper_words</th>\n",
       "      <th>toxicity_category</th>\n",
       "      <th>comment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>thi cool it's lik would want moth read real gr...</td>\n",
       "      <td>[thi, cool, it's, lik, would, want, moth, read...</td>\n",
       "      <td>[this cool, cool it's, it's like, like would, ...</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>thank thi would mak lif lot less anxy induc ke...</td>\n",
       "      <td>[thank, thi, would, mak, lif, lot, less, anxy,...</td>\n",
       "      <td>[thank this, this would, would make, make life...</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0.3640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>thi urg design problem kudo tak very impress</td>\n",
       "      <td>[thi, urg, design, problem, kudo, tak, very, i...</td>\n",
       "      <td>[this urgent, urgent design, design problem, p...</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>is someth i'll abl instal sit when releas</td>\n",
       "      <td>[is, someth, i'll, abl, instal, sit, when, rel...</td>\n",
       "      <td>[is something, something i'll, i'll able, able...</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>hah guy bunch los</td>\n",
       "      <td>[hah, guy, bunch, los]</td>\n",
       "      <td>[haha guys, guys bunch, bunch losers]</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id               target  \\\n",
       "0  59848               0.0000   \n",
       "1  59849               0.0000   \n",
       "2  59852               0.0000   \n",
       "3  59855               0.0000   \n",
       "4  59856               0.8936   \n",
       "\n",
       "                                        comment_text      severe_toxicity  \\\n",
       "0  This is so cool. It's like, 'would you want yo...               0.0000   \n",
       "1  Thank you!! This would make my life a lot less...               0.0000   \n",
       "2  This is such an urgent design problem; kudos t...               0.0000   \n",
       "3  Is this something I'll be able to install on m...               0.0000   \n",
       "4               haha you guys are a bunch of losers.               0.0213   \n",
       "\n",
       "               obscene      identity_attack               insult  \\\n",
       "0               0.0000               0.0000               0.0000   \n",
       "1               0.0000               0.0000               0.0000   \n",
       "2               0.0000               0.0000               0.0000   \n",
       "3               0.0000               0.0000               0.0000   \n",
       "4               0.0000               0.0213               0.8723   \n",
       "\n",
       "                threat                asian              atheist  ...  \\\n",
       "0               0.0000                  nan                  nan  ...   \n",
       "1               0.0000                  nan                  nan  ...   \n",
       "2               0.0000                  nan                  nan  ...   \n",
       "3               0.0000                  nan                  nan  ...   \n",
       "4               0.0000               0.0000               0.0000  ...   \n",
       "\n",
       "                               cleaned_lancaster_str  \\\n",
       "0  thi cool it's lik would want moth read real gr...   \n",
       "1  thank thi would mak lif lot less anxy induc ke...   \n",
       "2       thi urg design problem kudo tak very impress   \n",
       "3          is someth i'll abl instal sit when releas   \n",
       "4                                  hah guy bunch los   \n",
       "\n",
       "                                   cleaned_lancaster  \\\n",
       "0  [thi, cool, it's, lik, would, want, moth, read...   \n",
       "1  [thank, thi, would, mak, lif, lot, less, anxy,...   \n",
       "2  [thi, urg, design, problem, kudo, tak, very, i...   \n",
       "3  [is, someth, i'll, abl, instal, sit, when, rel...   \n",
       "4                             [hah, guy, bunch, los]   \n",
       "\n",
       "                                   bigrams_unstemmed           perc_upper  \\\n",
       "0  [this cool, cool it's, it's like, like would, ...               0.0300   \n",
       "1  [thank this, this would, would make, make life...               0.0260   \n",
       "2  [this urgent, urgent design, design problem, p...               0.0230   \n",
       "3  [is something, something i'll, i'll able, able...               0.0360   \n",
       "4              [haha guys, guys bunch, bunch losers]               0.0000   \n",
       "\n",
       "   num_exclam  num_words       perc_stopwords  num_upper_words  \\\n",
       "0           1         19               0.3160                0   \n",
       "1           3         22               0.3640                0   \n",
       "2           1         16               0.5000                0   \n",
       "3           0         17               0.5290                0   \n",
       "4           0          8               0.5000                0   \n",
       "\n",
       "   toxicity_category  comment_length  \n",
       "0                  0             101  \n",
       "1                  0             114  \n",
       "2                  0              86  \n",
       "3                  0              84  \n",
       "4                  1              36  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = ['perc_upper', 'num_exclam', 'num_words', 'perc_stopwords',\n",
    "       'num_upper_words', 'comment_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_upper - TOXIC\n",
      "count              5134.0000\n",
      "mean                  0.0377\n",
      "std                   0.0632\n",
      "min                   0.0000\n",
      "25%                   0.0170\n",
      "50%                   0.0260\n",
      "75%                   0.0410\n",
      "max                   1.0000\n",
      "Name: perc_upper, dtype: float64\n",
      "perc_upper - NONTOXIC\n",
      "count             94866.0000\n",
      "mean                  0.0360\n",
      "std                   0.0495\n",
      "min                   0.0000\n",
      "25%                   0.0170\n",
      "50%                   0.0260\n",
      "75%                   0.0400\n",
      "max                   1.0000\n",
      "Name: perc_upper, dtype: float64\n",
      "\n",
      "num_exclam - TOXIC\n",
      "count              5134.0000\n",
      "mean                  0.4024\n",
      "std                   1.3742\n",
      "min                   0.0000\n",
      "25%                   0.0000\n",
      "50%                   0.0000\n",
      "75%                   0.0000\n",
      "max                  37.0000\n",
      "Name: num_exclam, dtype: float64\n",
      "num_exclam - NONTOXIC\n",
      "count             94866.0000\n",
      "mean                  0.2480\n",
      "std                   0.9372\n",
      "min                   0.0000\n",
      "25%                   0.0000\n",
      "50%                   0.0000\n",
      "75%                   0.0000\n",
      "max                  64.0000\n",
      "Name: num_exclam, dtype: float64\n",
      "\n",
      "num_words - TOXIC\n",
      "count              5134.0000\n",
      "mean                 46.8099\n",
      "std                  42.2542\n",
      "min                   1.0000\n",
      "25%                  16.0000\n",
      "50%                  33.0000\n",
      "75%                  62.0000\n",
      "max                 370.0000\n",
      "Name: num_words, dtype: float64\n",
      "num_words - NONTOXIC\n",
      "count             94866.0000\n",
      "mean                 54.7727\n",
      "std                  48.9290\n",
      "min                   1.0000\n",
      "25%                  17.0000\n",
      "50%                  38.0000\n",
      "75%                  78.0000\n",
      "max                 501.0000\n",
      "Name: num_words, dtype: float64\n",
      "\n",
      "perc_stopwords - TOXIC\n",
      "count              5134.0000\n",
      "mean                  0.3963\n",
      "std                   0.1132\n",
      "min                  -1.0000\n",
      "25%                   0.3480\n",
      "50%                   0.4120\n",
      "75%                   0.4640\n",
      "max                   0.9350\n",
      "Name: perc_stopwords, dtype: float64\n",
      "perc_stopwords - NONTOXIC\n",
      "count             94866.0000\n",
      "mean                  0.3914\n",
      "std                   0.2203\n",
      "min                 -17.0000\n",
      "25%                   0.3540\n",
      "50%                   0.4170\n",
      "75%                   0.4670\n",
      "max                   1.0000\n",
      "Name: perc_stopwords, dtype: float64\n",
      "\n",
      "num_upper_words - TOXIC\n",
      "count              5134.0000\n",
      "mean                  1.3259\n",
      "std                   5.9792\n",
      "min                   0.0000\n",
      "25%                   0.0000\n",
      "50%                   0.0000\n",
      "75%                   1.0000\n",
      "max                 170.0000\n",
      "Name: num_upper_words, dtype: float64\n",
      "num_upper_words - NONTOXIC\n",
      "count             94866.0000\n",
      "mean                  1.2349\n",
      "std                   2.5577\n",
      "min                   0.0000\n",
      "25%                   0.0000\n",
      "50%                   1.0000\n",
      "75%                   2.0000\n",
      "max                 149.0000\n",
      "Name: num_upper_words, dtype: float64\n",
      "\n",
      "comment_length - TOXIC\n",
      "count              5134.0000\n",
      "mean                261.4182\n",
      "std                 235.6276\n",
      "min                   3.0000\n",
      "25%                  90.0000\n",
      "50%                 184.0000\n",
      "75%                 349.0000\n",
      "max                1000.0000\n",
      "Name: comment_length, dtype: float64\n",
      "comment_length - NONTOXIC\n",
      "count             94866.0000\n",
      "mean                310.0191\n",
      "std                 277.1413\n",
      "min                   1.0000\n",
      "25%                  97.0000\n",
      "50%                 213.0000\n",
      "75%                 438.0000\n",
      "max                1906.0000\n",
      "Name: comment_length, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in continuous_features:\n",
    "    print(feature + \" - TOXIC\")\n",
    "    print(toxic[feature].describe())\n",
    "\n",
    "    print(feature + \" - NONTOXIC\")\n",
    "    print(nontoxic[feature].describe())\n",
    "    \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
