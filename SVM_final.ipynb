{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was run on an Amazon SageMaker ml.c5.4xlarge instance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import LancasterStemmer \n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle_functions as pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_functions as mf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and shuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in test.csv and train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pf.read_pickle(bucket_name='advancedml-koch-mathur-hinkson', filename='sub_train_df14_preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['split', 'cleaned_w_stopwords', 'cleaned_no_stem', 'cleaned_porter', 'cleaned_lancaster', 'bigrams_unstemmed',\n",
    "       'perc_upper', 'num_exclam', 'num_words', 'perc_stopwords',\n",
    "       'num_upper_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 49)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
       "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
       "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
       "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
       "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
       "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
       "       'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count',\n",
       "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
       "       'cleaned_lancaster_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column called \"toxicity_category\" in the train data frame categorizing comments as toxic (\"1\") or non-toxic (\"0\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['toxicity_category'] = train.target.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train.csv into training (80%) and hold out sets (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citation: https://stackoverflow.com/questions/24147278/how-do-i-create-test-and-train-samples-from-one-dataframe-with-pandas\n",
    "msk = np.random.rand(len(train)) < 0.8\n",
    "train_set = train[msk]\n",
    "hold_out_set = train[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    74666\n",
      "1     5338\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18678\n",
      "1     1318\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(hold_out_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    74666\n",
      "1     5338\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_set.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = train_set[train_set.toxicity_category == 1]\n",
    "nontoxic = train_set[train_set.toxicity_category == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80004, 50), (5338, 50), (74666, 50))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, toxic.shape, nontoxic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the dataset to be include an equal number of toxic and nontoxic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter = len(toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = train_set.sample(quarter*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data set of 25% toxic and 75% nontoxic comments, and shuffle the data such that you do not have a data set of grouped toxic and grouped nontoxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    16014\n",
      "1     5338\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prepared_25 = toxic.append(nontoxic.sample(len(toxic)*3))\n",
    "prepared_25 = prepared_25.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_25.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - weighted 1/3 toxic, 2/3 nontoxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10664\n",
      "1     5332\n",
      "Name: toxicity_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prepared_33 = toxic.append(nontoxic.sample(len(toxic)*2))\n",
    "prepared_33 = prepared_33.sample(frac=1).reset_index(drop=True)\n",
    "print(prepared_33.toxicity_category.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model now\n"
     ]
    }
   ],
   "source": [
    "classifier, output, fitted_vectorizer = mf.run_model(model_df=prepared_33, \n",
    "                                                     model_type=\"SVM\", \n",
    "                                                     comments = \"cleaned_no_stem_str\", \n",
    "                                                     train_perc=0.95, \n",
    "                                                     target=\"toxicity_category\", \n",
    "                                                     see_inside=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
      "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
      "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
      "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
      "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
      "       'other_sexual_orientation', 'physical_disability',\n",
      "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
      "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
      "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
      "       'identity_annotator_count', 'toxicity_annotator_count',\n",
      "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
      "       'cleaned_lancaster_str', 'toxicity_category', 'predicted', 'y_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hold_out_results = mf.run_model_test(model_df=hold_out_set, \n",
    "                                     clf=classifier, \n",
    "                                     vectorizer=fitted_vectorizer, \n",
    "                                     comments=\"cleaned_no_stem_str\", target=\"toxicity_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9248949845639961\n",
      "Overall Precision: 0.45987963891675027\n",
      "Overall Recall: 0.6925981873111783\n",
      "Overall F1 Score: 0.5527426160337553\n",
      "ROC_AUC: 0.817\n",
      "\n",
      "Target Accuracy: 0.6925981873111783\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.6925981873111783\n",
      "Target F1 Score: 0.8183846497099508\n",
      "\n",
      "Non-Target Accuracy: 0.9415785191212368\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.9415785191212368\n",
      "Non-Target F1 Score: 0.9699103176598776\n",
      "\n",
      "Strong Identity Accuracy: 0.6535433070866141\n",
      "Strong Identity Precision: 0.9425287356321839\n",
      "Strong Identity Recall: 0.6776859504132231\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.7611940298507462\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.7611940298507462\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.742914979757085\n",
      "Insults Precision: 0.9849108367626886\n",
      "Insults Recall: 0.7471383975026015\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.3793103448275862\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.35714285714285715\n",
      "Threats F1 Score: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hold_out_metrics = mf.get_metrics(output=hold_out_results, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - weighted 25% toxic, 75% nontoxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model now\n"
     ]
    }
   ],
   "source": [
    "classifier, output, fitted_vectorizer = mf.run_model(model_df=prepared_25, \n",
    "                                                     model_type=\"SVM\", \n",
    "                                                     comments = \"cleaned_no_stem_str\", \n",
    "                                                     train_perc=0.95, \n",
    "                                                     target=\"toxicity_category\", \n",
    "                                                     see_inside=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>cleaned_w_stopwords_str</th>\n",
       "      <th>cleaned_no_stem_str</th>\n",
       "      <th>cleaned_porter_str</th>\n",
       "      <th>cleaned_lancaster_str</th>\n",
       "      <th>toxicity_category</th>\n",
       "      <th>predicted</th>\n",
       "      <th>y_test</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20284</th>\n",
       "      <td>5714292</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>It was stated in the same tone as when Barack ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>It was stated in the same tone as when Barack ...</td>\n",
       "      <td>it stated tone barack hussein obama stated nat...</td>\n",
       "      <td>it state tone barack hussein obama state natio...</td>\n",
       "      <td>it stat ton barack hussein obam stat nat tv th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>5820925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>It would be nice to know from the population w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>It would be nice to know from the population w...</td>\n",
       "      <td>it would nice know population whether thinks c...</td>\n",
       "      <td>it would nice know popul whether think cost wo...</td>\n",
       "      <td>it would nic know pop wheth think cost wor man...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20286</th>\n",
       "      <td>5751293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>\"That never attended one?\"  I never bothered w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>That never attended one  I never bothered with...</td>\n",
       "      <td>that never attended one i never bothered colle...</td>\n",
       "      <td>that never attend one i never bother colleg ev...</td>\n",
       "      <td>that nev attend on i nev both colleg ev i know...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20287</th>\n",
       "      <td>5763154</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>I'm actually kind of \"meh\" about statue remova...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>I'm actually kind of meh about statue removal ...</td>\n",
       "      <td>i'm actually kind meh statue removal i felt st...</td>\n",
       "      <td>i'm actual kind meh statu remov i felt strongl...</td>\n",
       "      <td>i'm act kind meh statu remov i felt strongly w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20288</th>\n",
       "      <td>5719487</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>The study is flawed w/ its ratings for tickets...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>The study is flawed w its ratings for tickets ...</td>\n",
       "      <td>the study flawed w ratings tickets running red...</td>\n",
       "      <td>the studi flaw w rate ticket run red light her...</td>\n",
       "      <td>the study flaw w rat ticket run red light her ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20289</th>\n",
       "      <td>5715631</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Are you also suggesting therefore that Roman C...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Are you also suggesting therefore that Roman C...</td>\n",
       "      <td>are also suggesting therefore roman catholics ...</td>\n",
       "      <td>are also suggest therefor roman cathol jew sho...</td>\n",
       "      <td>ar also suggest theref rom cathol jew should n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20290</th>\n",
       "      <td>5719524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>We are building a refinery. With huge governme...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>We are building a refinery With huge governmen...</td>\n",
       "      <td>we building refinery with huge government subs...</td>\n",
       "      <td>we build refineri with huge govern subsidi and...</td>\n",
       "      <td>we build refinery with hug govern subsidy and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20291</th>\n",
       "      <td>5796769</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>I think the guy is a creep, but please list th...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>I think the guy is a creep but please list the...</td>\n",
       "      <td>i think guy creep please list crime would/coul...</td>\n",
       "      <td>i think guy creep pleas list crime would/could...</td>\n",
       "      <td>i think guy creep pleas list crim would/could ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20292</th>\n",
       "      <td>5816815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>You actually have the answer. It's knowledge. ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>You actually have the answer It's knowledge Kn...</td>\n",
       "      <td>you actually answer it's knowledge knowledge c...</td>\n",
       "      <td>you actual answer it' knowledg knowledg creat ...</td>\n",
       "      <td>you act answ it's knowledg knowledg cre weal m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20293</th>\n",
       "      <td>5787192</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>Anyone who doesn't think they won't go after W...</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>Anyone who doesn't think they won't go after W...</td>\n",
       "      <td>anyone think won't go washington jefferson pig...</td>\n",
       "      <td>anyon think won't go washington jefferson pig ...</td>\n",
       "      <td>anyon think won't go washington jefferson pig ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target                                       comment_text  \\\n",
       "20284  5714292  0.600000  It was stated in the same tone as when Barack ...   \n",
       "20285  5820925  0.000000  It would be nice to know from the population w...   \n",
       "20286  5751293  0.000000  \"That never attended one?\"  I never bothered w...   \n",
       "20287  5763154  0.200000  I'm actually kind of \"meh\" about statue remova...   \n",
       "20288  5719487  0.200000  The study is flawed w/ its ratings for tickets...   \n",
       "20289  5715631  0.400000  Are you also suggesting therefore that Roman C...   \n",
       "20290  5719524  0.000000  We are building a refinery. With huge governme...   \n",
       "20291  5796769  0.600000  I think the guy is a creep, but please list th...   \n",
       "20292  5816815  0.000000  You actually have the answer. It's knowledge. ...   \n",
       "20293  5787192  0.657143  Anyone who doesn't think they won't go after W...   \n",
       "\n",
       "       severe_toxicity   obscene  identity_attack    insult    threat  asian  \\\n",
       "20284         0.000000  0.100000         0.100000  0.500000  0.000000    NaN   \n",
       "20285         0.000000  0.000000         0.000000  0.000000  0.000000    NaN   \n",
       "20286         0.000000  0.000000         0.000000  0.000000  0.000000    NaN   \n",
       "20287         0.000000  0.000000         0.100000  0.200000  0.000000    0.0   \n",
       "20288         0.000000  0.000000         0.000000  0.200000  0.000000    NaN   \n",
       "20289         0.000000  0.000000         0.400000  0.200000  0.100000    0.0   \n",
       "20290         0.000000  0.000000         0.000000  0.000000  0.000000    NaN   \n",
       "20291         0.100000  0.100000         0.000000  0.600000  0.000000    NaN   \n",
       "20292         0.000000  0.000000         0.000000  0.000000  0.000000    0.0   \n",
       "20293         0.057143  0.057143         0.285714  0.642857  0.014286    0.0   \n",
       "\n",
       "       atheist  ...  identity_annotator_count  toxicity_annotator_count  \\\n",
       "20284      NaN  ...                         0                        10   \n",
       "20285      NaN  ...                         0                         4   \n",
       "20286      NaN  ...                         0                         4   \n",
       "20287      0.0  ...                         5                        10   \n",
       "20288      NaN  ...                         0                        10   \n",
       "20289      0.0  ...                         4                        10   \n",
       "20290      NaN  ...                         0                         4   \n",
       "20291      NaN  ...                         0                        10   \n",
       "20292      0.0  ...                         5                         4   \n",
       "20293      0.0  ...                         4                        70   \n",
       "\n",
       "                                 cleaned_w_stopwords_str  \\\n",
       "20284  It was stated in the same tone as when Barack ...   \n",
       "20285  It would be nice to know from the population w...   \n",
       "20286  That never attended one  I never bothered with...   \n",
       "20287  I'm actually kind of meh about statue removal ...   \n",
       "20288  The study is flawed w its ratings for tickets ...   \n",
       "20289  Are you also suggesting therefore that Roman C...   \n",
       "20290  We are building a refinery With huge governmen...   \n",
       "20291  I think the guy is a creep but please list the...   \n",
       "20292  You actually have the answer It's knowledge Kn...   \n",
       "20293  Anyone who doesn't think they won't go after W...   \n",
       "\n",
       "                                     cleaned_no_stem_str  \\\n",
       "20284  it stated tone barack hussein obama stated nat...   \n",
       "20285  it would nice know population whether thinks c...   \n",
       "20286  that never attended one i never bothered colle...   \n",
       "20287  i'm actually kind meh statue removal i felt st...   \n",
       "20288  the study flawed w ratings tickets running red...   \n",
       "20289  are also suggesting therefore roman catholics ...   \n",
       "20290  we building refinery with huge government subs...   \n",
       "20291  i think guy creep please list crime would/coul...   \n",
       "20292  you actually answer it's knowledge knowledge c...   \n",
       "20293  anyone think won't go washington jefferson pig...   \n",
       "\n",
       "                                      cleaned_porter_str  \\\n",
       "20284  it state tone barack hussein obama state natio...   \n",
       "20285  it would nice know popul whether think cost wo...   \n",
       "20286  that never attend one i never bother colleg ev...   \n",
       "20287  i'm actual kind meh statu remov i felt strongl...   \n",
       "20288  the studi flaw w rate ticket run red light her...   \n",
       "20289  are also suggest therefor roman cathol jew sho...   \n",
       "20290  we build refineri with huge govern subsidi and...   \n",
       "20291  i think guy creep pleas list crime would/could...   \n",
       "20292  you actual answer it' knowledg knowledg creat ...   \n",
       "20293  anyon think won't go washington jefferson pig ...   \n",
       "\n",
       "                                   cleaned_lancaster_str  toxicity_category  \\\n",
       "20284  it stat ton barack hussein obam stat nat tv th...                  1   \n",
       "20285  it would nic know pop wheth think cost wor man...                  0   \n",
       "20286  that nev attend on i nev both colleg ev i know...                  0   \n",
       "20287  i'm act kind meh statu remov i felt strongly w...                  0   \n",
       "20288  the study flaw w rat ticket run red light her ...                  0   \n",
       "20289  ar also suggest theref rom cathol jew should n...                  0   \n",
       "20290  we build refinery with hug govern subsidy and ...                  0   \n",
       "20291  i think guy creep pleas list crim would/could ...                  1   \n",
       "20292  you act answ it's knowledg knowledg cre weal m...                  0   \n",
       "20293  anyon think won't go washington jefferson pig ...                  1   \n",
       "\n",
       "       predicted  y_test  accuracy  \n",
       "20284          0       1     False  \n",
       "20285          1       0     False  \n",
       "20286          0       0      True  \n",
       "20287          0       0      True  \n",
       "20288          0       0      True  \n",
       "20289          0       0      True  \n",
       "20290          0       0      True  \n",
       "20291          0       1     False  \n",
       "20292          0       0      True  \n",
       "20293          1       1      True  \n",
       "\n",
       "[10 rows x 53 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8857677902621723\n",
      "Overall Precision: 0.9042553191489362\n",
      "Overall Recall: 0.6204379562043796\n",
      "Overall F1 Score: 0.7359307359307359\n",
      "ROC_AUC: 0.799\n",
      "\n",
      "Target Accuracy: 0.6204379562043796\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.6204379562043796\n",
      "Target F1 Score: 0.7657657657657658\n",
      "\n",
      "Non-Target Accuracy: 0.9773299748110831\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.9773299748110831\n",
      "Non-Target F1 Score: 0.9885350318471338\n",
      "\n",
      "Strong Identity Accuracy: 0.5555555555555556\n",
      "Strong Identity Precision: 1.0\n",
      "Strong Identity Recall: 0.5555555555555556\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.7857142857142857\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.7857142857142857\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.671875\n",
      "Insults Precision: 0.9923076923076923\n",
      "Insults Recall: 0.675392670157068\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.5714285714285714\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.5714285714285714\n",
      "Threats F1 Score: 1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Overall': {'Accuracy': 0.8857677902621723,\n",
       "  'Precision': 0.9042553191489362,\n",
       "  'Recall': 0.6204379562043796,\n",
       "  'F1': 0.7359307359307359,\n",
       "  'ROC_AUC': 0.799},\n",
       " 'Target': {'Accuracy': 0.6204379562043796,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.6204379562043796,\n",
       "  'F1': 0.7657657657657658},\n",
       " 'Non-Target': {'Accuracy': 0.5714285714285714,\n",
       "  'Precision': 1.0,\n",
       "  'Recall': 0.5714285714285714,\n",
       "  'F1': 1.0}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.get_metrics(output=output, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'target', 'comment_text', 'severe_toxicity', 'obscene',\n",
      "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
      "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
      "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
      "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
      "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
      "       'other_sexual_orientation', 'physical_disability',\n",
      "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
      "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
      "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
      "       'identity_annotator_count', 'toxicity_annotator_count',\n",
      "       'cleaned_w_stopwords_str', 'cleaned_no_stem_str', 'cleaned_porter_str',\n",
      "       'cleaned_lancaster_str', 'toxicity_category', 'predicted', 'y_test'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "hold_out_results = mf.run_model_test(model_df=hold_out_set, \n",
    "                                     clf=classifier, \n",
    "                                     vectorizer=fitted_vectorizer, \n",
    "                                     comments=\"cleaned_no_stem_str\", target=\"toxicity_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold_out_results.to_csv(\"holdout_results\", sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9451890378075615\n",
      "Overall Precision: 0.5786118980169972\n",
      "Overall Recall: 0.6198786039453718\n",
      "Overall F1 Score: 0.5985347985347984\n",
      "ROC_AUC: 0.794\n",
      "\n",
      "Target Accuracy: 0.6198786039453718\n",
      "Target Precision: 1.0\n",
      "Target Recall: 0.6198786039453718\n",
      "Target F1 Score: 0.7653395784543325\n",
      "\n",
      "Non-Target Accuracy: 0.9681443409358603\n",
      "Non-Target Precision: 1.0\n",
      "Non-Target Recall: 0.9681443409358603\n",
      "Non-Target F1 Score: 0.9838143684883436\n",
      "\n",
      "Strong Identity Accuracy: 0.5740740740740741\n",
      "Strong Identity Precision: 0.9482758620689655\n",
      "Strong Identity Recall: 0.5612244897959183\n",
      "Strong Identity F1 Score: 1.0\n",
      "\n",
      "Obscenity Accuracy: 0.6521739130434783\n",
      "Obscenity Precision: 1.0\n",
      "Obscenity Recall: 0.6521739130434783\n",
      "Obscenity F1 Score: 1.0\n",
      "\n",
      "Insults Accuracy: 0.7070193285859614\n",
      "Insults Precision: 0.9912917271407837\n",
      "Insults Recall: 0.7077720207253886\n",
      "Insults F1 Score: 1.0\n",
      "\n",
      "Threats Accuracy: 0.24\n",
      "Threats Precision: 1.0\n",
      "Threats Recall: 0.24\n",
      "Threats F1 Score: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hold_out_metrics = mf.get_metrics(output=hold_out_results, detailed=True, should_print=True, round_to=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = classifier.coef_.todense().tolist()[0]\n",
    "imp2, names = zip(*sorted(zip(imp,feature_names)))\n",
    "\n",
    "top_pos = np,\n",
    "plt.barh(range(len(names)), names)\n",
    "plt.yticks(range(len(names)), names)\n",
    "plt.show()\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = imp2[-10:] + imp2[:10]\n",
    "words = names[-10:] + names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tograph = pd.DataFrame()\n",
    "tograph['importances'] = imps\n",
    "tograph['words'] = words\n",
    "tograph['type'] = tograph.importances.apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b4a7369e8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"importances\", y=\"words\", data=tograph, hue=\"type\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
